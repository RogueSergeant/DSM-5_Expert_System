{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Diagnostic Decision Support System for Mental Health Assessment\n",
    "\n",
    "**Module:** Foundations of AI  \n",
    "**Deadline:** 5th January 2026\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook implements a **Category 3 Hybrid Approach** combining:\n",
    "- **Symbolic reasoning** (Prolog expert system) for objective diagnostic criteria\n",
    "- **Stochastic methods** (LLM) for knowledge extraction and subjective assessment\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Layer 1: Knowledge Base Construction (LLM → Prolog)\n",
    "    DSM-5 Text → LLM Extraction → Prolog Rules\n",
    "                     ↓\n",
    "Layer 2: Three-Tier Diagnostic Reasoning\n",
    "    Tier A: Objective (Prolog) - symptom counts, duration, onset\n",
    "    Tier B: Subjective (LLM) - clinical significance, severity\n",
    "    Tier C: Integration (Prolog) - ranked diagnoses + explanations\n",
    "                     ↓\n",
    "Layer 3: Diagnostic Pathway Search (A*)\n",
    "    Optimised question ordering with branch pruning\n",
    "```\n",
    "\n",
    "### Target Disorders\n",
    "\n",
    "| Disorder | Key Challenge | Complexity |\n",
    "|----------|---------------|------------|\n",
    "| MDD | Count-based (5/9), 2-week duration | Medium |\n",
    "| GAD | Subjective \"excessive worry\" | Medium |\n",
    "| ADHD | Onset before 12, dual domains | High |\n",
    "| PTSD | Trauma criterion, symptom clusters | High |\n",
    "| ASD | Severity levels, developmental history | High |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "### 1.1 Imports and Configuration\n",
    "\n",
    "We use **pyswip** to interface Python with SWI-Prolog. This allows us to:\n",
    "- Load Prolog knowledge bases\n",
    "- Assert patient facts dynamically\n",
    "- Query diagnostic rules and retrieve explanations\n",
    "\n",
    "**Design Decision:** We chose pyswip over alternatives like janus because:\n",
    "- Better documentation and community support\n",
    "- Simpler API for our use case\n",
    "- Compatible with SWI-Prolog 9.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI\n",
      "Prolog directory: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Prolog interface\n",
    "from pyswip import Prolog\n",
    "\n",
    "# Progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path('../').resolve()\n",
    "PROLOG_DIR = PROJECT_ROOT / 'src' / 'prolog'\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DSM5_TEXT_DIR = DATA_DIR / 'dsm5_text'\n",
    "VIGNETTES_DIR = DATA_DIR / 'vignettes'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Prolog directory: {PROLOG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prolog Engine Initialisation\n",
    "\n",
    "We create a wrapper class around pyswip's Prolog interface to:\n",
    "- Handle file path resolution\n",
    "- Provide cleaner query methods\n",
    "- Manage patient fact assertions/retractions\n",
    "\n",
    "**Design Decision:** Wrapping pyswip rather than using it directly provides:\n",
    "- Consistent error handling\n",
    "- Easier testing and mocking\n",
    "- Cleaner separation between Python and Prolog concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrologEngine:\n",
    "    \"\"\"Wrapper around pyswip Prolog for diagnostic reasoning.\"\"\"\n",
    "    \n",
    "    def __init__(self, prolog_dir: Path):\n",
    "        self.prolog = Prolog()\n",
    "        self.prolog_dir = prolog_dir\n",
    "        self._loaded_files = set()\n",
    "    \n",
    "    def load_file(self, filename: str) -> bool:\n",
    "        \"\"\"Load a Prolog file from the prolog directory.\"\"\"\n",
    "        filepath = self.prolog_dir / filename\n",
    "        if not filepath.exists():\n",
    "            print(f\"Error: File not found: {filepath}\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # pyswip requires forward slashes even on Windows\n",
    "            prolog_path = str(filepath).replace('\\\\', '/')\n",
    "            self.prolog.consult(prolog_path)\n",
    "            self._loaded_files.add(filename)\n",
    "            print(f\"Loaded: {filename}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def query(self, query_str: str) -> List[Dict]:\n",
    "        \"\"\"Execute a Prolog query and return results as list of dicts.\"\"\"\n",
    "        try:\n",
    "            results = list(self.prolog.query(query_str))\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Query error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def query_one(self, query_str: str) -> Optional[Dict]:\n",
    "        \"\"\"Execute a query and return first result or None.\"\"\"\n",
    "        results = self.query(query_str)\n",
    "        return results[0] if results else None\n",
    "    \n",
    "    def assert_fact(self, fact: str) -> bool:\n",
    "        \"\"\"Assert a fact into the Prolog knowledge base.\"\"\"\n",
    "        try:\n",
    "            list(self.prolog.query(f\"assertz({fact})\"))\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Assert error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def retract_all(self, pattern: str) -> bool:\n",
    "        \"\"\"Retract all facts matching a pattern.\"\"\"\n",
    "        try:\n",
    "            list(self.prolog.query(f\"retractall({pattern})\"))\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Retract error: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load Schema and Gold Standard\n",
    "\n",
    "We load:\n",
    "1. **schema.pl** - Core predicate definitions and diagnostic inference rules\n",
    "2. **gold_standard/loader.pl** - Hand-coded disorder criteria (ground truth)\n",
    "\n",
    "The gold standard serves two purposes:\n",
    "- Validation target for LLM extraction accuracy\n",
    "- Fallback knowledge base if extraction quality is insufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: schema.pl\n",
      "Loaded: mdd\n",
      "Loaded: gold_standard/loader.pl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:13:\n",
      "Warning:    Local definition of user:disorder/3 overrides weak import from dsm5_schema\n",
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:27:\n",
      "Warning:    Local definition of user:symptom/4 overrides weak import from dsm5_schema\n",
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:67:\n",
      "Warning:    Local definition of user:symptom_category/5 overrides weak import from dsm5_schema\n",
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:82:\n",
      "Warning:    Local definition of user:duration_requirement/3 overrides weak import from dsm5_schema\n",
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:90:\n",
      "Warning:    Local definition of user:onset_requirement/3 overrides weak import from dsm5_schema\n",
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:102:\n",
      "Warning:    Local definition of user:exclusion_criterion/4 overrides weak import from dsm5_schema\n",
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:126:\n",
      "Warning:    Local definition of user:subjective_criterion/4 overrides weak import from dsm5_schema\n",
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:136:\n",
      "Warning:    Local definition of user:specifier/4 overrides weak import from dsm5_schema\n",
      "Warning: /Users/alfieroberts/Documents/Applied AI MSc/Coursework/Foundations of AI/src/prolog/gold_standard/mdd.pl:164:\n",
      "Warning:    Local definition of user:differential_feature/4 overrides weak import from dsm5_schema\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise Prolog engine\n",
    "engine = PrologEngine(PROLOG_DIR)\n",
    "\n",
    "# Load schema and gold standard\n",
    "engine.load_file('schema.pl')\n",
    "engine.load_file('gold_standard/loader.pl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Verify Knowledge Base\n",
    "\n",
    "Quick sanity check to ensure the knowledge base loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all loaded disorders\n",
    "disorders = engine.query(\"disorder(ID, Name, Category)\")\n",
    "print(\"Loaded Disorders:\")\n",
    "for d in disorders:\n",
    "    print(f\"  - {d['ID']}: {d['Name']} ({d['Category']})\")\n",
    "\n",
    "# Count symptoms per disorder\n",
    "print(\"\\nSymptom Counts:\")\n",
    "for d in disorders:\n",
    "    disorder_id = d['ID']\n",
    "    symptoms = engine.query(f\"symptom({disorder_id}, SID, Cat, Desc)\")\n",
    "    print(f\"  - {disorder_id}: {len(symptoms)} symptoms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Knowledge Base Exploration\n",
    "\n",
    "### 2.1 Schema Structure\n",
    "\n",
    "The Prolog schema defines the following predicate types:\n",
    "\n",
    "| Predicate | Arity | Purpose |\n",
    "|-----------|-------|----------|\n",
    "| `disorder/3` | ID, Name, Category | Disorder definitions |\n",
    "| `symptom/4` | DisorderID, SymptomID, Category, Description | Individual symptoms |\n",
    "| `symptom_category/5` | DisorderID, CategoryID, SymptomList, Count, Type | Grouping requirements |\n",
    "| `duration_requirement/3` | DisorderID, Duration, Unit | Time constraints |\n",
    "| `onset_requirement/3` | DisorderID, Type, Value | Onset constraints |\n",
    "| `exclusion_criterion/4` | DisorderID, ExclusionID, Type, Description | What must NOT be present |\n",
    "| `subjective_criterion/4` | DisorderID, CriterionID, Description, Type | Requires clinical judgment |\n",
    "| `specifier/4` | DisorderID, Type, Options, Description | Diagnosis qualifiers |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_disorder(engine: PrologEngine, disorder_id: str) -> Dict:\n",
    "    \"\"\"Extract all knowledge about a disorder from the KB.\"\"\"\n",
    "    return {\n",
    "        'disorder': engine.query_one(f\"disorder({disorder_id}, Name, Category)\"),\n",
    "        'symptoms': engine.query(f\"symptom({disorder_id}, SID, Cat, Desc)\"),\n",
    "        'symptom_categories': engine.query(f\"symptom_category({disorder_id}, CatID, Symptoms, Count, Type)\"),\n",
    "        'duration': engine.query_one(f\"duration_requirement({disorder_id}, Dur, Unit)\"),\n",
    "        'onset': engine.query_one(f\"onset_requirement({disorder_id}, Type, Value)\"),\n",
    "        'exclusions': engine.query(f\"exclusion_criterion({disorder_id}, ExcID, Type, Desc)\"),\n",
    "        'subjective': engine.query(f\"subjective_criterion({disorder_id}, CritID, Desc, Type)\"),\n",
    "        'specifiers': engine.query(f\"specifier({disorder_id}, Type, Options, Desc)\")\n",
    "    }\n",
    "\n",
    "# Explore MDD\n",
    "mdd_kb = explore_disorder(engine, 'mdd')\n",
    "print(\"MDD Knowledge Base Summary:\")\n",
    "print(f\"  Symptoms: {len(mdd_kb['symptoms'])}\")\n",
    "print(f\"  Symptom categories: {len(mdd_kb['symptom_categories'])}\")\n",
    "print(f\"  Duration: {mdd_kb['duration']}\")\n",
    "print(f\"  Exclusions: {len(mdd_kb['exclusions'])}\")\n",
    "print(f\"  Subjective criteria: {len(mdd_kb['subjective'])}\")\n",
    "print(f\"  Specifiers: {len(mdd_kb['specifiers'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualise Disorder Structure\n",
    "\n",
    "Using NetworkX to visualise the relationships between symptoms, categories, and criteria.\n",
    "\n",
    "**Design Decision:** NetworkX was chosen for ontology visualisation because:\n",
    "- Native Python integration\n",
    "- Can be used for semantic validation (detecting contradictions)\n",
    "- Supports graph algorithms for pathway search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_disorder_graph(disorder_data: Dict) -> nx.DiGraph:\n",
    "    \"\"\"Build a NetworkX graph representing disorder structure.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    disorder_id = disorder_data['disorder']['ID']\n",
    "    disorder_name = disorder_data['disorder']['Name']\n",
    "    \n",
    "    # Add disorder node\n",
    "    G.add_node(disorder_id, type='disorder', label=disorder_name)\n",
    "    \n",
    "    # Add symptom nodes\n",
    "    for sym in disorder_data['symptoms']:\n",
    "        sym_id = sym['SID']\n",
    "        G.add_node(sym_id, type='symptom', category=sym['Cat'])\n",
    "        G.add_edge(disorder_id, sym_id, relation='has_symptom')\n",
    "    \n",
    "    # Add exclusion nodes\n",
    "    for exc in disorder_data['exclusions']:\n",
    "        exc_id = exc['ExcID']\n",
    "        G.add_node(exc_id, type='exclusion')\n",
    "        G.add_edge(disorder_id, exc_id, relation='excludes')\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Build and visualise MDD graph\n",
    "mdd_graph = build_disorder_graph(mdd_kb)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(mdd_graph, k=2, iterations=50)\n",
    "\n",
    "# Color nodes by type\n",
    "node_colors = []\n",
    "for node in mdd_graph.nodes():\n",
    "    node_type = mdd_graph.nodes[node].get('type', 'unknown')\n",
    "    if node_type == 'disorder':\n",
    "        node_colors.append('#e74c3c')\n",
    "    elif node_type == 'symptom':\n",
    "        node_colors.append('#3498db')\n",
    "    elif node_type == 'exclusion':\n",
    "        node_colors.append('#f39c12')\n",
    "    else:\n",
    "        node_colors.append('#95a5a6')\n",
    "\n",
    "nx.draw(mdd_graph, pos, node_color=node_colors, with_labels=True, \n",
    "        node_size=500, font_size=8, arrows=True)\n",
    "plt.title('MDD Knowledge Structure')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. LLM Extraction Pipeline\n",
    "\n",
    "### 3.1 Extraction Architecture\n",
    "\n",
    "The LLM extraction pipeline converts DSM-5 text into Prolog rules:\n",
    "\n",
    "```\n",
    "DSM-5 Text → Prompt Engineering → LLM → Raw Output → Parser → Prolog Rules → Validation\n",
    "```\n",
    "\n",
    "**Design Decisions:**\n",
    "- **Structured output format:** We request Prolog syntax directly to minimise post-processing\n",
    "- **Few-shot prompting:** Include examples from gold standard to guide extraction\n",
    "- **Validation pipeline:** Syntactic (Prolog compilation) + Semantic (ontology consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configure your LLM here\n",
    "# Options: Local Llama via llama.cpp, Ollama, or API-based\n",
    "\n",
    "class LLMConfig:\n",
    "    \"\"\"Configuration for LLM extraction.\"\"\"\n",
    "    MODEL_NAME: str = \"llama3.1:8b\"  # or \"llama3.1:70b\" for better accuracy\n",
    "    TEMPERATURE: float = 0.1  # Low temperature for consistent extraction\n",
    "    MAX_TOKENS: int = 4096\n",
    "    \n",
    "print(f\"LLM Config: {LLMConfig.MODEL_NAME}\")\n",
    "print(\"Note: Update LLMConfig with your local model settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Extraction Prompt Template\n",
    "\n",
    "The prompt is structured in XML format (optimised for Claude/Llama) with:\n",
    "1. **System context** - Role and output format\n",
    "2. **Schema reference** - Available predicates\n",
    "3. **Few-shot examples** - From gold standard\n",
    "4. **Input** - DSM-5 text to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTION_PROMPT_TEMPLATE = \"\"\"\n",
    "<system>\n",
    "You are a medical knowledge engineer extracting DSM-5 diagnostic criteria into Prolog format.\n",
    "Output ONLY valid Prolog syntax. Use lowercase atoms and quoted strings for descriptions.\n",
    "</system>\n",
    "\n",
    "<schema>\n",
    "Available predicates:\n",
    "- disorder(DisorderID, 'Full Name', category).\n",
    "- symptom(DisorderID, symptom_id, category, 'Description').\n",
    "- symptom_category(DisorderID, category_id, [symptom_list], required_count, requirement_type).\n",
    "- duration_requirement(DisorderID, number, unit).  % unit: days, weeks, months\n",
    "- onset_requirement(DisorderID, constraint_type, value).  % e.g., before_age, after_event, any\n",
    "- exclusion_criterion(DisorderID, exclusion_id, type, 'Description').  % type: substance, medical, other_disorder\n",
    "- subjective_criterion(DisorderID, criterion_id, 'Description', assessment_type).  % type: clinical_significance, excessiveness, severity\n",
    "- specifier(DisorderID, specifier_type, [options], 'Description').\n",
    "</schema>\n",
    "\n",
    "<example>\n",
    "Input: Major Depressive Disorder requires 5 of 9 symptoms for 2 weeks...\n",
    "Output:\n",
    "disorder(mdd, 'Major Depressive Disorder', depressive_disorders).\n",
    "symptom(mdd, mdd_a1, core, 'Depressed mood most of the day, nearly every day').\n",
    "symptom_category(mdd, all_symptoms, [mdd_a1, mdd_a2, ...], 5, at_least).\n",
    "duration_requirement(mdd, 2, weeks).\n",
    "</example>\n",
    "\n",
    "<input>\n",
    "Disorder ID: {disorder_id}\n",
    "DSM-5 Text:\n",
    "{dsm5_text}\n",
    "</input>\n",
    "\n",
    "<instructions>\n",
    "Extract ALL criteria from the text above into Prolog format.\n",
    "Include: symptoms, duration, onset requirements, exclusions, subjective criteria, and specifiers.\n",
    "Output ONLY Prolog facts, no explanations.\n",
    "</instructions>\n",
    "\"\"\"\n",
    "\n",
    "def build_extraction_prompt(disorder_id: str, dsm5_text: str) -> str:\n",
    "    \"\"\"Build the extraction prompt for a disorder.\"\"\"\n",
    "    return EXTRACTION_PROMPT_TEMPLATE.format(\n",
    "        disorder_id=disorder_id,\n",
    "        dsm5_text=dsm5_text\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 DSM-5 Text Loading\n",
    "\n",
    "Load the raw DSM-5 criteria text from the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dsm5_text(disorder_id: str) -> Optional[str]:\n",
    "    \"\"\"Load DSM-5 text for a disorder.\"\"\"\n",
    "    # Try common filename patterns\n",
    "    patterns = [\n",
    "        f\"{disorder_id.upper()}.txt\",\n",
    "        f\"{disorder_id.lower()}.txt\",\n",
    "        f\"{disorder_id}.txt\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        filepath = DSM5_TEXT_DIR / pattern\n",
    "        if filepath.exists():\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "    \n",
    "    print(f\"Warning: No DSM-5 text found for {disorder_id}\")\n",
    "    return None\n",
    "\n",
    "# List available DSM-5 texts\n",
    "print(\"Available DSM-5 texts:\")\n",
    "for f in DSM5_TEXT_DIR.glob(\"*.txt\"):\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Extraction Validation\n",
    "\n",
    "Extracted rules must pass two validation stages:\n",
    "\n",
    "1. **Syntactic validation** - Prolog compilation succeeds\n",
    "2. **Semantic validation** - Rules are consistent with schema ontology\n",
    "\n",
    "**Design Decision:** We validate before adding to the KB to prevent corruption of the reasoning engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ValidationResult:\n",
    "    \"\"\"Result of validating extracted Prolog rules.\"\"\"\n",
    "    is_valid: bool\n",
    "    syntactic_errors: List[str] = field(default_factory=list)\n",
    "    semantic_errors: List[str] = field(default_factory=list)\n",
    "    warnings: List[str] = field(default_factory=list)\n",
    "\n",
    "def validate_extraction(prolog_rules: str, engine: PrologEngine) -> ValidationResult:\n",
    "    \"\"\"Validate extracted Prolog rules.\"\"\"\n",
    "    result = ValidationResult(is_valid=True)\n",
    "    \n",
    "    # TODO: Implement syntactic validation\n",
    "    # - Write rules to temp file\n",
    "    # - Attempt Prolog compilation\n",
    "    # - Capture any errors\n",
    "    \n",
    "    # TODO: Implement semantic validation\n",
    "    # - Check symptom IDs are unique\n",
    "    # - Check symptom categories reference valid symptoms\n",
    "    # - Check no contradictory rules\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Validation framework ready (implementation pending)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Diagnostic Reasoning Engine\n",
    "\n",
    "### 4.1 Three-Tier Architecture\n",
    "\n",
    "The diagnostic engine implements three tiers:\n",
    "\n",
    "| Tier | Handler | Criteria Type | Method |\n",
    "|------|---------|---------------|--------|\n",
    "| A | Prolog | Objective | Rule-based inference |\n",
    "| B | LLM | Subjective | Clinical judgment with confidence |\n",
    "| C | Prolog | Integration | Combine A+B for final diagnosis |\n",
    "\n",
    "**Design Decision:** Separating objective and subjective criteria allows:\n",
    "- Transparent reasoning chains for objective criteria\n",
    "- Appropriate uncertainty quantification for subjective criteria\n",
    "- Clinician override capability for Tier B assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymptomStatus(Enum):\n",
    "    \"\"\"Status of a symptom for a patient.\"\"\"\n",
    "    PRESENT = \"present\"\n",
    "    ABSENT = \"absent\"\n",
    "    UNCLEAR = \"unclear\"\n",
    "\n",
    "@dataclass\n",
    "class PatientSymptom:\n",
    "    \"\"\"A symptom observation for a patient.\"\"\"\n",
    "    symptom_id: str\n",
    "    status: SymptomStatus\n",
    "    evidence: str  # Quote from clinical notes\n",
    "\n",
    "@dataclass\n",
    "class SubjectiveAssessment:\n",
    "    \"\"\"LLM or clinician assessment of a subjective criterion.\"\"\"\n",
    "    criterion_id: str\n",
    "    assessment: str  # \"met\", \"not_met\", \"unclear\"\n",
    "    confidence: float  # 0.0 to 1.0\n",
    "    reasoning: str\n",
    "\n",
    "@dataclass \n",
    "class DiagnosisResult:\n",
    "    \"\"\"Result of diagnostic reasoning.\"\"\"\n",
    "    disorder_id: str\n",
    "    disorder_name: str\n",
    "    is_diagnosed: bool\n",
    "    confidence: float\n",
    "    criteria_met: Dict[str, bool]\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Patient Case Manager\n",
    "\n",
    "Manages patient facts in the Prolog knowledge base:\n",
    "- Assert symptoms from clinical input\n",
    "- Track duration and onset information\n",
    "- Record exclusion status\n",
    "- Store subjective assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientCaseManager:\n",
    "    \"\"\"Manages patient facts in the Prolog KB.\"\"\"\n",
    "    \n",
    "    def __init__(self, engine: PrologEngine):\n",
    "        self.engine = engine\n",
    "        self.current_patient_id: Optional[str] = None\n",
    "    \n",
    "    def clear_patient(self, patient_id: str):\n",
    "        \"\"\"Clear all facts for a patient.\"\"\"\n",
    "        patterns = [\n",
    "            f\"patient_symptom({patient_id}, _, _, _)\",\n",
    "            f\"patient_duration({patient_id}, _, _)\",\n",
    "            f\"patient_onset_age({patient_id}, _)\",\n",
    "            f\"patient_exclusion_status({patient_id}, _, _)\",\n",
    "            f\"subjective_assessment({patient_id}, _, _, _)\",\n",
    "            f\"patient_context({patient_id}, _, _)\"\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            self.engine.retract_all(pattern)\n",
    "    \n",
    "    def load_patient(self, patient_id: str, symptoms: List[PatientSymptom],\n",
    "                     duration_days: Dict[str, int],\n",
    "                     onset_age: Optional[int] = None):\n",
    "        \"\"\"Load a patient case into the KB.\"\"\"\n",
    "        self.clear_patient(patient_id)\n",
    "        self.current_patient_id = patient_id\n",
    "        \n",
    "        # Assert symptoms\n",
    "        for sym in symptoms:\n",
    "            fact = f\"patient_symptom({patient_id}, {sym.symptom_id}, {sym.status.value}, '{sym.evidence}')\"\n",
    "            self.engine.assert_fact(fact)\n",
    "        \n",
    "        # Assert durations\n",
    "        for disorder_id, days in duration_days.items():\n",
    "            fact = f\"patient_duration({patient_id}, {disorder_id}, {days})\"\n",
    "            self.engine.assert_fact(fact)\n",
    "        \n",
    "        # Assert onset age if provided\n",
    "        if onset_age is not None:\n",
    "            fact = f\"patient_onset_age({patient_id}, {onset_age})\"\n",
    "            self.engine.assert_fact(fact)\n",
    "    \n",
    "    def add_subjective_assessment(self, patient_id: str, assessment: SubjectiveAssessment):\n",
    "        \"\"\"Add a subjective assessment to the KB.\"\"\"\n",
    "        fact = f\"subjective_assessment({patient_id}, {assessment.criterion_id}, {assessment.assessment}, {assessment.confidence})\"\n",
    "        self.engine.assert_fact(fact)\n",
    "\n",
    "# Initialise patient manager\n",
    "patient_manager = PatientCaseManager(engine)\n",
    "print(\"Patient case manager ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Tier A: Objective Reasoning\n",
    "\n",
    "Queries Prolog for objective criteria evaluation:\n",
    "- Symptom count requirements\n",
    "- Duration requirements\n",
    "- Onset requirements\n",
    "- Exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectiveReasoner:\n",
    "    \"\"\"Tier A: Objective criteria evaluation via Prolog.\"\"\"\n",
    "    \n",
    "    def __init__(self, engine: PrologEngine):\n",
    "        self.engine = engine\n",
    "    \n",
    "    def check_symptom_criteria(self, patient_id: str, disorder_id: str) -> Tuple[bool, Dict]:\n",
    "        \"\"\"Check if symptom count criteria are met.\"\"\"\n",
    "        result = self.engine.query_one(\n",
    "            f\"meets_symptom_criteria({patient_id}, {disorder_id})\"\n",
    "        )\n",
    "        \n",
    "        # Get detailed symptom counts\n",
    "        present = self.engine.query(\n",
    "            f\"patient_symptom({patient_id}, SID, present, _), symptom({disorder_id}, SID, _, _)\"\n",
    "        )\n",
    "        \n",
    "        return result is not None, {'present_count': len(present)}\n",
    "    \n",
    "    def check_duration_criteria(self, patient_id: str, disorder_id: str) -> Tuple[bool, Dict]:\n",
    "        \"\"\"Check if duration criteria are met.\"\"\"\n",
    "        result = self.engine.query_one(\n",
    "            f\"meets_duration_criteria({patient_id}, {disorder_id})\"\n",
    "        )\n",
    "        return result is not None, {}\n",
    "    \n",
    "    def check_onset_criteria(self, patient_id: str, disorder_id: str) -> Tuple[bool, Dict]:\n",
    "        \"\"\"Check if onset criteria are met.\"\"\"\n",
    "        result = self.engine.query_one(\n",
    "            f\"meets_onset_criteria({patient_id}, {disorder_id})\"\n",
    "        )\n",
    "        return result is not None, {}\n",
    "    \n",
    "    def check_exclusion_criteria(self, patient_id: str, disorder_id: str) -> Tuple[bool, Dict]:\n",
    "        \"\"\"Check if exclusion criteria are satisfied (no exclusions apply).\"\"\"\n",
    "        result = self.engine.query_one(\n",
    "            f\"meets_exclusion_criteria({patient_id}, {disorder_id})\"\n",
    "        )\n",
    "        return result is not None, {}\n",
    "    \n",
    "    def evaluate_all(self, patient_id: str, disorder_id: str) -> Dict[str, Tuple[bool, Dict]]:\n",
    "        \"\"\"Evaluate all objective criteria.\"\"\"\n",
    "        return {\n",
    "            'symptoms': self.check_symptom_criteria(patient_id, disorder_id),\n",
    "            'duration': self.check_duration_criteria(patient_id, disorder_id),\n",
    "            'onset': self.check_onset_criteria(patient_id, disorder_id),\n",
    "            'exclusions': self.check_exclusion_criteria(patient_id, disorder_id)\n",
    "        }\n",
    "\n",
    "# Initialise objective reasoner\n",
    "objective_reasoner = ObjectiveReasoner(engine)\n",
    "print(\"Objective reasoner ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Tier B: Subjective Assessment\n",
    "\n",
    "Uses LLM to evaluate subjective criteria based on clinical notes.\n",
    "\n",
    "**Design Decision:** Subjective assessments include:\n",
    "- Confidence scores (0-1) for calibration\n",
    "- Evidence quotes for transparency\n",
    "- Reasoning chains for clinician review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECTIVE_ASSESSMENT_PROMPT = \"\"\"\n",
    "<task>\n",
    "Assess whether the following subjective criterion is met based on the clinical notes.\n",
    "</task>\n",
    "\n",
    "<criterion>\n",
    "ID: {criterion_id}\n",
    "Description: {criterion_description}\n",
    "Assessment Type: {assessment_type}\n",
    "</criterion>\n",
    "\n",
    "<clinical_notes>\n",
    "{clinical_notes}\n",
    "</clinical_notes>\n",
    "\n",
    "<instructions>\n",
    "Respond in JSON format:\n",
    "{{\n",
    "    \"assessment\": \"met\" | \"not_met\" | \"unclear\",\n",
    "    \"confidence\": 0.0-1.0,\n",
    "    \"evidence\": \"quote from notes supporting assessment\",\n",
    "    \"reasoning\": \"brief explanation of clinical judgment\"\n",
    "}}\n",
    "</instructions>\n",
    "\"\"\"\n",
    "\n",
    "class SubjectiveAssessor:\n",
    "    \"\"\"Tier B: Subjective criteria assessment via LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client=None):\n",
    "        self.llm = llm_client  # TODO: Inject LLM client\n",
    "    \n",
    "    def assess(self, criterion_id: str, criterion_description: str,\n",
    "               assessment_type: str, clinical_notes: str) -> SubjectiveAssessment:\n",
    "        \"\"\"Assess a subjective criterion.\"\"\"\n",
    "        \n",
    "        # TODO: Call LLM with prompt\n",
    "        # For now, return placeholder\n",
    "        return SubjectiveAssessment(\n",
    "            criterion_id=criterion_id,\n",
    "            assessment=\"unclear\",\n",
    "            confidence=0.5,\n",
    "            reasoning=\"LLM assessment not yet implemented\"\n",
    "        )\n",
    "    \n",
    "    def assess_all_for_disorder(self, disorder_id: str, clinical_notes: str,\n",
    "                                 engine: PrologEngine) -> List[SubjectiveAssessment]:\n",
    "        \"\"\"Assess all subjective criteria for a disorder.\"\"\"\n",
    "        criteria = engine.query(f\"subjective_criterion({disorder_id}, CritID, Desc, Type)\")\n",
    "        \n",
    "        assessments = []\n",
    "        for crit in criteria:\n",
    "            assessment = self.assess(\n",
    "                criterion_id=crit['CritID'],\n",
    "                criterion_description=crit['Desc'],\n",
    "                assessment_type=crit['Type'],\n",
    "                clinical_notes=clinical_notes\n",
    "            )\n",
    "            assessments.append(assessment)\n",
    "        \n",
    "        return assessments\n",
    "\n",
    "# Initialise subjective assessor\n",
    "subjective_assessor = SubjectiveAssessor()\n",
    "print(\"Subjective assessor ready (LLM integration pending)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Tier C: Diagnostic Integration\n",
    "\n",
    "Combines Tier A and Tier B results into final diagnosis with explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosticIntegrator:\n",
    "    \"\"\"Tier C: Integrate objective and subjective results.\"\"\"\n",
    "    \n",
    "    def __init__(self, engine: PrologEngine, objective: ObjectiveReasoner,\n",
    "                 subjective: SubjectiveAssessor, patient_mgr: PatientCaseManager):\n",
    "        self.engine = engine\n",
    "        self.objective = objective\n",
    "        self.subjective = subjective\n",
    "        self.patient_mgr = patient_mgr\n",
    "    \n",
    "    def diagnose(self, patient_id: str, disorder_id: str,\n",
    "                 clinical_notes: str = \"\") -> DiagnosisResult:\n",
    "        \"\"\"Run full diagnostic evaluation.\"\"\"\n",
    "        \n",
    "        # Get disorder info\n",
    "        disorder_info = self.engine.query_one(f\"disorder({disorder_id}, Name, _)\")\n",
    "        if not disorder_info:\n",
    "            return DiagnosisResult(\n",
    "                disorder_id=disorder_id,\n",
    "                disorder_name=\"Unknown\",\n",
    "                is_diagnosed=False,\n",
    "                confidence=0.0,\n",
    "                criteria_met={},\n",
    "                explanation=f\"Disorder {disorder_id} not found in knowledge base\"\n",
    "            )\n",
    "        \n",
    "        # Tier A: Objective evaluation\n",
    "        objective_results = self.objective.evaluate_all(patient_id, disorder_id)\n",
    "        \n",
    "        # Tier B: Subjective evaluation\n",
    "        subjective_results = self.subjective.assess_all_for_disorder(\n",
    "            disorder_id, clinical_notes, self.engine\n",
    "        )\n",
    "        \n",
    "        # Add subjective assessments to KB\n",
    "        for assessment in subjective_results:\n",
    "            self.patient_mgr.add_subjective_assessment(patient_id, assessment)\n",
    "        \n",
    "        # Tier C: Integration via Prolog\n",
    "        diagnosis_result = self.engine.query_one(\n",
    "            f\"diagnosis_candidate({patient_id}, {disorder_id}, Confidence)\"\n",
    "        )\n",
    "        \n",
    "        # Build explanation\n",
    "        criteria_met = {\n",
    "            'symptoms': objective_results['symptoms'][0],\n",
    "            'duration': objective_results['duration'][0],\n",
    "            'onset': objective_results['onset'][0],\n",
    "            'exclusions': objective_results['exclusions'][0],\n",
    "            'subjective': all(a.assessment == 'met' for a in subjective_results)\n",
    "        }\n",
    "        \n",
    "        is_diagnosed = diagnosis_result is not None\n",
    "        confidence = diagnosis_result['Confidence'] if diagnosis_result else 0.0\n",
    "        \n",
    "        explanation = self._build_explanation(disorder_id, criteria_met, objective_results)\n",
    "        \n",
    "        return DiagnosisResult(\n",
    "            disorder_id=disorder_id,\n",
    "            disorder_name=disorder_info['Name'],\n",
    "            is_diagnosed=is_diagnosed,\n",
    "            confidence=confidence,\n",
    "            criteria_met=criteria_met,\n",
    "            explanation=explanation\n",
    "        )\n",
    "    \n",
    "    def _build_explanation(self, disorder_id: str, criteria_met: Dict,\n",
    "                           objective_results: Dict) -> str:\n",
    "        \"\"\"Build human-readable explanation.\"\"\"\n",
    "        lines = [f\"Diagnostic evaluation for {disorder_id.upper()}:\"]\n",
    "        \n",
    "        for criterion, met in criteria_met.items():\n",
    "            status = \"MET\" if met else \"NOT MET\"\n",
    "            lines.append(f\"  - {criterion.title()}: {status}\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "# Initialise integrator\n",
    "integrator = DiagnosticIntegrator(engine, objective_reasoner, subjective_assessor, patient_manager)\n",
    "print(\"Diagnostic integrator ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Diagnostic Pathway Search\n",
    "\n",
    "### 5.1 A* Search for Optimal Question Ordering\n",
    "\n",
    "The pathway search finds the optimal sequence of questions to reach a diagnosis:\n",
    "\n",
    "- **State:** Current diagnostic certainty (disorders confirmed/excluded/pending)\n",
    "- **Operators:** Criterion evaluations (objective checks or subjective queries)\n",
    "- **Heuristic:** Estimated remaining evaluations to definitive diagnosis\n",
    "\n",
    "**Design Decision:** A* search prioritises:\n",
    "1. Screening criteria first (broad elimination)\n",
    "2. Discriminating features between remaining candidates\n",
    "3. Subjective criteria last (most expensive to evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class DiagnosticState:\n",
    "    \"\"\"State in diagnostic pathway search.\"\"\"\n",
    "    confirmed: set = field(default_factory=set)\n",
    "    excluded: set = field(default_factory=set)\n",
    "    pending: set = field(default_factory=set)\n",
    "    evidence: Dict = field(default_factory=dict)\n",
    "    questions_asked: int = 0\n",
    "    \n",
    "    def is_terminal(self) -> bool:\n",
    "        \"\"\"Check if we've reached a definitive state.\"\"\"\n",
    "        return len(self.pending) <= 1 or len(self.confirmed) > 0\n",
    "    \n",
    "    def copy(self) -> 'DiagnosticState':\n",
    "        \"\"\"Create a copy of this state.\"\"\"\n",
    "        return DiagnosticState(\n",
    "            confirmed=self.confirmed.copy(),\n",
    "            excluded=self.excluded.copy(),\n",
    "            pending=self.pending.copy(),\n",
    "            evidence=self.evidence.copy(),\n",
    "            questions_asked=self.questions_asked\n",
    "        )\n",
    "\n",
    "@dataclass(order=True)\n",
    "class SearchNode:\n",
    "    \"\"\"Node in A* search priority queue.\"\"\"\n",
    "    priority: float\n",
    "    state: DiagnosticState = field(compare=False)\n",
    "    path: List[str] = field(compare=False, default_factory=list)\n",
    "\n",
    "class PathwaySearch:\n",
    "    \"\"\"A* search for optimal diagnostic pathway.\"\"\"\n",
    "    \n",
    "    def __init__(self, engine: PrologEngine, all_disorders: List[str]):\n",
    "        self.engine = engine\n",
    "        self.all_disorders = set(all_disorders)\n",
    "    \n",
    "    def heuristic(self, state: DiagnosticState) -> float:\n",
    "        \"\"\"Estimate remaining questions needed.\"\"\"\n",
    "        # Simple heuristic: 2 questions per pending disorder\n",
    "        return len(state.pending) * 2\n",
    "    \n",
    "    def get_next_questions(self, state: DiagnosticState) -> List[str]:\n",
    "        \"\"\"Get candidate questions for current state.\"\"\"\n",
    "        questions = []\n",
    "        \n",
    "        # Prioritise screening questions first\n",
    "        # TODO: Implement question generation based on pending disorders\n",
    "        \n",
    "        return questions\n",
    "    \n",
    "    def apply_evidence(self, state: DiagnosticState, question: str,\n",
    "                       answer: Any) -> DiagnosticState:\n",
    "        \"\"\"Apply evidence from answered question to state.\"\"\"\n",
    "        new_state = state.copy()\n",
    "        new_state.evidence[question] = answer\n",
    "        new_state.questions_asked += 1\n",
    "        \n",
    "        # TODO: Implement pruning logic\n",
    "        # e.g., if trauma_exposure == False, exclude PTSD\n",
    "        \n",
    "        return new_state\n",
    "    \n",
    "    def search(self, initial_evidence: Dict = None) -> Tuple[List[str], DiagnosticState]:\n",
    "        \"\"\"Find optimal question sequence.\"\"\"\n",
    "        initial_state = DiagnosticState(\n",
    "            pending=self.all_disorders.copy(),\n",
    "            evidence=initial_evidence or {}\n",
    "        )\n",
    "        \n",
    "        # A* search\n",
    "        frontier = []\n",
    "        heappush(frontier, SearchNode(\n",
    "            priority=self.heuristic(initial_state),\n",
    "            state=initial_state,\n",
    "            path=[]\n",
    "        ))\n",
    "        \n",
    "        while frontier:\n",
    "            node = heappop(frontier)\n",
    "            \n",
    "            if node.state.is_terminal():\n",
    "                return node.path, node.state\n",
    "            \n",
    "            # Expand node\n",
    "            # TODO: Implement expansion\n",
    "        \n",
    "        return [], initial_state\n",
    "\n",
    "print(\"Pathway search framework ready (implementation pending)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Evaluation\n",
    "\n",
    "### 6.1 Evaluation Metrics\n",
    "\n",
    "| Category | Metric | Target |\n",
    "|----------|--------|--------|\n",
    "| KB Extraction | Precision/Recall vs gold standard | >85% |\n",
    "| Objective Reasoning | Diagnostic accuracy (clear cases) | >90% |\n",
    "| Subjective Assessment | LLM suggestion acceptance rate | >70% |\n",
    "| Integrated System | Top-2 accuracy (all cases) | >90% |\n",
    "| Pathway Search | Question reduction vs exhaustive | >40% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvaluationMetrics:\n",
    "    \"\"\"Container for evaluation metrics.\"\"\"\n",
    "    # KB Extraction\n",
    "    extraction_precision: float = 0.0\n",
    "    extraction_recall: float = 0.0\n",
    "    extraction_f1: float = 0.0\n",
    "    \n",
    "    # Diagnostic Accuracy\n",
    "    clear_case_accuracy: float = 0.0\n",
    "    top2_accuracy: float = 0.0\n",
    "    \n",
    "    # Pathway Efficiency\n",
    "    avg_questions_asked: float = 0.0\n",
    "    question_reduction_pct: float = 0.0\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            'extraction': {\n",
    "                'precision': self.extraction_precision,\n",
    "                'recall': self.extraction_recall,\n",
    "                'f1': self.extraction_f1\n",
    "            },\n",
    "            'diagnostic': {\n",
    "                'clear_case_accuracy': self.clear_case_accuracy,\n",
    "                'top2_accuracy': self.top2_accuracy\n",
    "            },\n",
    "            'pathway': {\n",
    "                'avg_questions': self.avg_questions_asked,\n",
    "                'reduction_pct': self.question_reduction_pct\n",
    "            }\n",
    "        }\n",
    "\n",
    "def calculate_f1(precision: float, recall: float) -> float:\n",
    "    \"\"\"Calculate F1 score from precision and recall.\"\"\"\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Evaluation metrics framework ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Test Case Loading\n",
    "\n",
    "Load synthetic vignettes for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TestCase:\n",
    "    \"\"\"A synthetic test vignette.\"\"\"\n",
    "    case_id: str\n",
    "    vignette_text: str\n",
    "    ground_truth_diagnosis: str\n",
    "    case_type: str  # \"clear\", \"moderate\", \"ambiguous\"\n",
    "    symptoms_present: List[str]\n",
    "    symptoms_absent: List[str]\n",
    "\n",
    "def load_test_cases(vignettes_dir: Path) -> List[TestCase]:\n",
    "    \"\"\"Load test cases from vignettes directory.\"\"\"\n",
    "    test_cases = []\n",
    "    \n",
    "    for filepath in vignettes_dir.glob(\"*.json\"):\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            test_cases.append(TestCase(**data))\n",
    "    \n",
    "    return test_cases\n",
    "\n",
    "# Load test cases if available\n",
    "test_cases = load_test_cases(VIGNETTES_DIR)\n",
    "print(f\"Loaded {len(test_cases)} test cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Baseline Implementations\n",
    "\n",
    "For comparison, we implement three baselines:\n",
    "\n",
    "1. **Keyword Matching** - Simple regex/keyword search (no reasoning)\n",
    "2. **LLM-Only** - Direct diagnosis from vignette without structured criteria\n",
    "3. **Prolog-Only** - No subjective tier (fails on GAD, struggles with ASD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordBaseline:\n",
    "    \"\"\"Baseline 1: Simple keyword matching.\"\"\"\n",
    "    \n",
    "    DISORDER_KEYWORDS = {\n",
    "        'mdd': ['depressed', 'sad', 'hopeless', 'worthless', 'suicidal', 'fatigue', 'insomnia'],\n",
    "        'gad': ['anxiety', 'worry', 'restless', 'nervous', 'tense'],\n",
    "        'adhd': ['inattention', 'hyperactive', 'impulsive', 'distracted', 'fidget'],\n",
    "        'ptsd': ['trauma', 'flashback', 'nightmare', 'avoidance', 'hypervigilant'],\n",
    "        'asd': ['social', 'communication', 'repetitive', 'routine', 'sensory']\n",
    "    }\n",
    "    \n",
    "    def diagnose(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"Return disorder with highest keyword match.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        scores = {}\n",
    "        \n",
    "        for disorder, keywords in self.DISORDER_KEYWORDS.items():\n",
    "            score = sum(1 for kw in keywords if kw in text_lower)\n",
    "            scores[disorder] = score / len(keywords)\n",
    "        \n",
    "        best = max(scores, key=scores.get)\n",
    "        return best, scores[best]\n",
    "\n",
    "print(\"Baseline implementations ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Run Evaluation\n",
    "\n",
    "Execute evaluation across all test cases and baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(test_cases: List[TestCase], integrator: DiagnosticIntegrator,\n",
    "                   baselines: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Run full evaluation suite.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for case in tqdm(test_cases, desc=\"Evaluating\"):\n",
    "        # TODO: Implement full evaluation loop\n",
    "        pass\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Evaluation framework ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Demo and Results\n",
    "\n",
    "### 7.1 Interactive Demo\n",
    "\n",
    "Demonstrate the system with a sample vignette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample MDD vignette for demonstration\n",
    "DEMO_VIGNETTE = \"\"\"\n",
    "Patient: 34-year-old female\n",
    "Chief Complaint: \"I just feel empty all the time.\"\n",
    "\n",
    "History of Present Illness:\n",
    "Patient reports persistent low mood for the past 3 weeks. She describes feeling \n",
    "\"sad and hopeless\" most of the day, nearly every day. She has lost interest in \n",
    "activities she previously enjoyed, including playing guitar and socialising with \n",
    "friends. She reports difficulty sleeping, waking at 4am and unable to return to \n",
    "sleep. She feels constantly fatigued despite reduced activity. She expresses \n",
    "feelings of worthlessness, stating \"I'm a burden to everyone.\" No suicidal \n",
    "ideation reported. Appetite is reduced but weight is stable.\n",
    "\n",
    "No history of substance abuse. No recent medication changes. No significant \n",
    "medical history. No prior manic or hypomanic episodes.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Demo vignette loaded\")\n",
    "print(DEMO_VIGNETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run demonstration diagnosis\n",
    "# 1. Extract symptoms from vignette (LLM)\n",
    "# 2. Load patient into KB\n",
    "# 3. Run diagnostic integrator\n",
    "# 4. Display results with explanation\n",
    "\n",
    "print(\"Demo execution pending - complete LLM integration first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Results Summary\n",
    "\n",
    "Placeholder for final evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate results tables and visualisations\n",
    "print(\"Results summary pending evaluation completion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusions and Future Work\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- TODO: Summarise main results\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- TODO: Document limitations\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "- TODO: Propose extensions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
