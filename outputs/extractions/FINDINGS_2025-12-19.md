# LLM Extraction Findings: PTSD Diagnostic Criteria

> **Note:** This detailed finding report has been reorganized into:
> - **Summary:** [docs/PROVIDER_EVALUATION.md](../../docs/PROVIDER_EVALUATION.md)
> - **Benchmarks:** [docs/EXTRACTION_BENCHMARKS.md](../../docs/EXTRACTION_BENCHMARKS.md)
>
> This file is retained for archival reference.

**Date:** 2025-12-19
**Task:** Extract DSM-5 PTSD diagnostic criteria into structured Prolog format
**Input:** `data/dsm5_text/PTSD.txt`
**Template:** `src/prolog/gold_standard/README.md`

---

## Executive Summary

Three LLM providers were tested for automated extraction of DSM-5 diagnostic criteria into Prolog format. All three produced syntactically valid output, but varied significantly in completeness and comprehensiveness.

**Recommendation:** Anthropic Claude Sonnet 4.5 produced the most complete extraction, including both adult and preschool criteria as separate disorders. OpenAI GPT-5.2 offers a good balance of speed and quality. Ollama gpt-oss:20b is viable for local/offline use but produces less comprehensive output.

---

## Test Configuration

### Primary Test (Low Thinking)

| Parameter | Value |
|-----------|-------|
| Thinking Level | Low (all providers) |
| OpenAI `reasoning_effort` | low |
| Anthropic `thinking_budget` | 5,000 tokens |
| Ollama `think` | low |
| Temperature | 1.0 (required by reasoning models) |
| Max Tokens | 16,384 |

### Follow-up Test (Medium Thinking - Ollama Only)

| Parameter | Value |
|-----------|-------|
| Ollama `think` | medium |
| All other parameters | Same as above |

---

## Results Summary

### Primary Test (Low Thinking)

| Provider | Model | Duration | Input Tokens | Output Tokens | File Size | Syntax Valid |
|----------|-------|----------|--------------|---------------|-----------|--------------|
| Ollama | gpt-oss:20b | 506.1s | 18,982 | 2,452 | 5.4 KB | Yes |
| OpenAI | gpt-5.2 | 67.0s | 18,656 | 4,115 | 15.2 KB | Yes |
| Anthropic | claude-sonnet-4-5 | 81.4s | 22,990 | 5,857 | 20.8 KB | Yes |

### Follow-up Test: Ollama Thinking Levels

| Provider | Model | Think Level | Duration | Input Tokens | Output Tokens | File Size | Syntax Valid |
|----------|-------|-------------|----------|--------------|---------------|-----------|--------------|
| Ollama | gpt-oss:20b | low | 506.1s | 18,982 | 2,452 | 5.4 KB | Yes |
| Ollama | gpt-oss:20b | medium | 626.4s | 18,982 | 3,118 | 5.8 KB | Yes |
| Ollama | gpt-oss:20b | high | 1345.5s | 18,982 | 7,646 | 4.5 KB | Yes |

**Observation:** High thinking took 166% longer than low (+839s) but still did not fix Criterion A gap.

### Follow-up Test: High Thinking (All Providers)

| Provider | Model | Think Level | Duration | Input Tokens | Output Tokens | Syntax Valid |
|----------|-------|-------------|----------|--------------|---------------|--------------|
| Ollama | gpt-oss:20b | high | 1345.5s | 18,982 | 7,646 | Yes |
| OpenAI | gpt-5.2 | high | 83.4s | 18,656 | 4,907 | Yes |
| Anthropic | claude-sonnet-4-5 | budget=15000 | 105.3s | 22,990 | 8,764 | Yes |

**Speed comparison:** OpenAI high was 16x faster than Ollama high.

---

## Detailed Comparison

### 1. Criterion Coverage

#### Low Thinking Level

| DSM-5 Criterion | Ollama (low) | OpenAI (low) | Anthropic (5k) |
|-----------------|--------------|--------------|----------------|
| **A: Trauma Exposure** (4 items) | Missing | 4/4 | 4/4 |
| **B: Intrusion** (5 items) | 5/5 | 5/5 | 5/5 |
| **C: Avoidance** (2 items) | 2/2 | 2/2 | 2/2 |
| **D: Negative Cognitions/Mood** (7 items) | 7/7 | 7/7 | 7/7 |
| **E: Arousal/Reactivity** (6 items) | 6/6 | 6/6 | 6/6 |
| **F: Duration** | Yes | Yes | Yes |
| **G: Clinical Significance** | Yes | Yes | Yes |
| **H: Exclusions** | 2 | 2 | 2 |
| **Preschool Criteria** | No | Yes (partial) | Yes (full) |

#### High Thinking Level

| DSM-5 Criterion | Ollama (high) | OpenAI (high) | Anthropic (15k) |
|-----------------|---------------|---------------|-----------------|
| **A: Trauma Exposure** (4 items) | **Missing** | 4/4 | 4/4 |
| **B: Intrusion** (5 items) | 5/5 | 5/5 | 5/5 |
| **C: Avoidance** (2 items) | 2/2 | 2/2 | 2/2 |
| **D: Negative Cognitions/Mood** (7 items) | 7/7 | 7/7 | 7/7 |
| **E: Arousal/Reactivity** (6 items) | 6/6 | 6/6 | 6/6 |
| **F: Duration** | Yes | Yes | Yes |
| **G: Clinical Significance** | Yes | Yes | Yes |
| **H: Exclusions** | 3 | 2 | 2 |
| **Preschool Criteria** | No | No | Yes (full) |

**Critical Finding:** Ollama's gpt-oss:20b consistently missed Criterion A (trauma exposure) at ALL thinking levels (low, medium, high). This appears to be a systematic model limitation, not a thinking depth issue. The model took 22+ minutes at high thinking but still failed to capture this critical diagnostic requirement.

### 2. Preschool Criteria (Children ≤6 years)

| Feature | Ollama | OpenAI | Anthropic |
|---------|--------|--------|-----------|
| Included | No | Partial | Full |
| Implementation | - | Extra symptoms in main disorder | Separate `ptsd_preschool` disorder |
| Separate symptom categories | - | No | Yes |
| Separate exclusions | - | No | Yes |

**Finding:** Anthropic correctly modeled preschool PTSD as a separate disorder with its own predicates, matching DSM-5 structure.

### 3. Specifiers

| Specifier | Ollama | OpenAI | Anthropic |
|-----------|--------|--------|-----------|
| Dissociative symptoms | Yes | Yes | Yes |
| Delayed expression | Yes | Yes | Yes |
| Severity | Yes | Yes | Yes |
| Developmental variant | No | No | Yes |

### 4. Differential Features

| Provider | Think Level | Count | Quality |
|----------|-------------|-------|---------|
| Ollama | low | 2 | Basic (MDD, GAD only) |
| Ollama | medium | 9 | Good (MDD, GAD, Adjustment, ASD, DID, Panic, Personality, Psychotic, TBI) |
| OpenAI | low | 12 | Comprehensive with detailed descriptions |
| Anthropic | low | 8 | Good coverage of key differentials |

**Finding:** OpenAI produced the most comprehensive differential diagnosis guidance. Ollama medium thinking significantly improved differential feature coverage (2 → 9), demonstrating that higher thinking levels can improve output quality for some aspects.

### 5. Code Quality

| Aspect | Ollama | OpenAI | Anthropic |
|--------|--------|--------|-----------|
| Header comments | Good | Excellent | Excellent |
| Section organization | Good | Excellent | Excellent |
| Inline documentation | Minimal | Detailed | Detailed |
| Consistent naming | Yes | Yes | Yes |
| DSM-5 code reference | No | Yes (309.81, F43.10) | Yes (309.81, F43.10) |

---

## Provider-Specific Observations

### Ollama (gpt-oss:20b)

**Strengths:**
- Local/offline operation (no API costs, data privacy)
- Valid Prolog syntax
- Correct symptom category structure

**Weaknesses:**
- Slowest by far (506-1345s vs 67-105s for cloud APIs)
- **Critical:** Missing Criterion A at all thinking levels (low/medium/high)
- No preschool criteria
- Inconsistent differential features across thinking levels
- No DSM-5 code reference

**Verdict:** Not recommended for PTSD extraction due to systematic Criterion A gap. The larger gpt-oss:120b model may resolve this issue but requires high-end hardware (64GB+ VRAM) not available on consumer devices like M4 MacBook Air.

### OpenAI (gpt-5.2)

**Strengths:**
- Fastest completion (67s)
- Complete adult criteria including Criterion A
- Most comprehensive differential features (12)
- Excellent documentation and comments
- Includes child-specific notes within symptoms

**Weaknesses:**
- Preschool criteria embedded as extra symptoms rather than separate disorder
- Requires API key and incurs costs

**Verdict:** Best balance of speed and quality for production use.

### Anthropic (claude-sonnet-4-5)

**Strengths:**
- Most complete output (20.8 KB)
- Correctly modeled preschool PTSD as separate disorder
- Full symptom categories for both adult and preschool
- Developmental variant specifier
- Excellent structure matching DSM-5 organization

**Weaknesses:**
- Slower than OpenAI (81s vs 67s)
- Requires API key and incurs costs
- Extended thinking required temperature=1.0 (less deterministic)

**Verdict:** Best for gold standard creation where completeness is paramount.

---

## Ollama Thinking Level Analysis

### Comparison: Low vs Medium vs High

| Metric | Low | Medium | High | Low→High Change |
|--------|-----|--------|------|-----------------|
| Duration | 506.1s | 626.4s | 1345.5s | +166% |
| Output Tokens | 2,452 | 3,118 | 7,646 | +212% |
| File Size | 5.4 KB | 5.8 KB | 4.5 KB | -17% |
| Criterion A | Missing | Missing | Missing | **No change** |
| Exclusion Criteria | 2 | 4 | 3 | +50% |
| Differential Features | 2 | 9 | 4 | +100% |
| Preschool Criteria | No | No | No | No change |

### Quality Changes Across Thinking Levels

**Low Thinking:**
- Basic output with minimal differentials
- Missing Criterion A

**Medium Thinking (+24% time):**
- More exclusion criteria (4 vs 2)
- More differential features (9 vs 2)
- Still missing Criterion A

**High Thinking (+166% time):**
- More output tokens but shorter file (redundancy removed?)
- Fewer differential features than medium (4 vs 9)
- Still missing Criterion A
- 22+ minutes processing time

### Critical Conclusion

**Criterion A is a systematic gap in gpt-oss:20b.** Despite:
- Testing all three thinking levels (low, medium, high)
- Processing times ranging from 8 to 22 minutes
- Output tokens ranging from 2,452 to 7,646

The model consistently fails to include Criterion A (trauma exposure), which is the foundational requirement for PTSD diagnosis. This is not a thinking depth issue—it appears to be a training or architecture limitation of this specific model.

**Recommendation:** Do NOT use Ollama gpt-oss:20b for PTSD extraction without manual addition of Criterion A. Consider testing other Ollama models (deepseek-r1, qwq) to see if this is model-specific.

### Hardware Limitations Note

The larger **gpt-oss:120b** model may produce better results with its expanded context window and parameter count, potentially capturing Criterion A correctly. However, this model requires significantly more VRAM than available on consumer hardware (tested on M4 MacBook Air with 16GB unified memory).

For users with access to:
- **High-end workstations** (64GB+ VRAM): Consider testing gpt-oss:120b
- **Cloud GPU instances**: May be cost-effective for batch processing vs API costs
- **Consumer hardware**: Stick with cloud APIs (OpenAI, Anthropic) for complete extractions

---

## Technical Issues Encountered

### 1. OpenAI GPT-5 API Changes
- `max_tokens` parameter deprecated; must use `max_completion_tokens`
- Temperature must be 1.0 when using `reasoning_effort` parameter
- Fixed in `openai_provider.py`

### 2. Anthropic Extended Thinking
- Requires `temperature=1.0` when thinking is enabled
- Minimum budget is 1,024 tokens
- Already handled in `anthropic_provider.py`

---

## Cost Comparison (Estimated)

| Provider | Input Cost | Output Cost | Total (this test) |
|----------|------------|-------------|-------------------|
| Ollama | $0.00 | $0.00 | $0.00 |
| OpenAI | ~$0.19 | ~$0.16 | ~$0.35 |
| Anthropic | ~$0.07 | ~$0.09 | ~$0.16 |

*Note: Costs estimated based on December 2025 pricing. Actual costs depend on current rates.*

---

## Recommendations

### For Gold Standard Creation
Use **Anthropic Claude Sonnet 4.5** with `thinking_budget=10000-15000`:
- Most complete output
- Correct handling of developmental variants
- Best structural fidelity to DSM-5

### For Batch Processing
Use **OpenAI GPT-5.2** with `reasoning_effort=medium`:
- Best speed/quality ratio
- Comprehensive differential features
- Good for processing multiple disorders

### For Offline/Local Use
Use **Ollama gpt-oss:20b** with `think=high`:
- No API costs
- Data stays local
- Requires manual review for completeness

### For Future Tests
1. Test with `think=high` / `reasoning_effort=high` to compare quality improvement
2. Test on more complex disorders (e.g., Schizophrenia, Bipolar)
3. Evaluate inter-rater reliability across multiple runs
4. Test smaller/faster models for cost optimisation

---

## Output Files

```
outputs/extractions/
├── ptsd_ollama_gpt-oss-20b_20251219_153819.pl      # Ollama think=low
├── ptsd_ollama_gpt-oss-20b_20251219_153819.json
├── ptsd_ollama_gpt-oss-20b_20251219_155838.pl      # Ollama think=medium
├── ptsd_ollama_gpt-oss-20b_20251219_155838.json
├── ptsd_ollama_gpt-oss-20b_20251219_163102.pl      # Ollama think=high
├── ptsd_ollama_gpt-oss-20b_20251219_163102.json
├── ptsd_openai_gpt-5.2_20251219_154221.pl          # OpenAI reasoning=low
├── ptsd_openai_gpt-5.2_20251219_154221.json
├── ptsd_openai_gpt-5.2_20251219_161002.pl          # OpenAI reasoning=high
├── ptsd_openai_gpt-5.2_20251219_161002.json
├── ptsd_anthropic_claude-sonnet-4-5_20251219_154020.pl  # Anthropic budget=5000
├── ptsd_anthropic_claude-sonnet-4-5_20251219_154020.json
├── ptsd_anthropic_claude-sonnet-4-5_20251219_161208.pl  # Anthropic budget=15000
├── ptsd_anthropic_claude-sonnet-4-5_20251219_161208.json
└── FINDINGS_2025-12-19.md
```

---

## Conclusion

All three providers successfully generated syntactically valid Prolog files from DSM-5 text. However, significant differences in completeness and structural accuracy were observed:

### Provider Rankings

1. **Anthropic Claude Sonnet 4.5** - Best overall
   - Most complete output with proper preschool criteria handling
   - Consistent quality across thinking levels
   - Moderate speed (81-105s)

2. **OpenAI GPT-5.2** - Best speed/quality ratio
   - Complete adult criteria with comprehensive differentials
   - Fastest provider (67-83s)
   - Good documentation in output

3. **Ollama gpt-oss:20b** - Not recommended for PTSD
   - **Critical gap:** Missing Criterion A at ALL thinking levels
   - Slowest provider (506-1345s)
   - May be viable for other disorders but requires validation

### Key Findings

| Finding | Implication |
|---------|-------------|
| Ollama missing Criterion A is systematic | Model limitation, not thinking depth issue |
| High thinking doesn't always improve quality | Medium may be optimal for Ollama |
| Anthropic preschool handling is superior | Best for complex developmental criteria |
| OpenAI is 16x faster than Ollama high | Cloud APIs significantly more efficient |

### Recommended Approach

For this hybrid diagnostic system:

1. **Gold Standard Creation:** Use Anthropic with budget=15000
2. **Rapid Iteration:** Use OpenAI with reasoning=medium
3. **Offline Development:** Avoid Ollama gpt-oss for PTSD; test other models
4. **Quality Assurance:** Always validate Criterion A presence manually for trauma disorders

### Next Steps

1. Test Anthropic output as the PTSD gold standard candidate
2. Test other Ollama models (deepseek-r1, qwq) for Criterion A handling
3. Run extraction on additional disorders (GAD, ADHD) to validate pipeline
4. Evaluate cost/quality tradeoffs for batch processing

The extraction pipeline is functional. Ollama has a critical limitation for PTSD specifically.
